"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"Smartphone based experience sampling of stress-related events","J. Weppner; P. Lukowicz; S. Serino; P. Cipresso; A. Gaggioli; G. Riva","German Research Center for Artificial Intelligence, Deutsche Forschungszentrum für Künstliche Intelligenz Kaiserslautern, Germany; German Research Center for Artificial Intelligence, Deutsche Forschungszentrum für Künstliche Intelligenz Kaiserslautern, Germany; Applied Technology for Neuro-Psychology Laboratory, IRCCS Istituto Auxologico Italiano, Milan, Italy; Applied Technology for Neuro-Psychology Laboratory, IRCCS Istituto Auxologico Italiano, Milan, Italy; Applied Technology for Neuro-Psychology Laboratory, IRCCS Istituto Auxologico Italiano, Milan, Italy; Applied Technology for Neuro-Psychology Laboratory, IRCCS Istituto Auxologico Italiano, Milan, Italy","2013 7th International Conference on Pervasive Computing Technologies for Healthcare and Workshops","22 Jul 2013","2013","","","464","467","Mobile phones are gaining particular importance in health care services. In fact, the incredible diffusion of mobile electronic devices has opened new scenarios for the assessment of stress-related events. We presented an Android Smartphone based experience sampling method and a real life data set containing stress related events. Data consisted of 12 weeks of 9 trial participants provided with Android Smartphone equipped with a specific experience sampling application.","2153-1641","978-1-936968-80-0","10.4108/icst.pervasivehealth.2013.252358","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6563991","Stress;Experience Sampling Method;ESM;Smartphone;Psychometrics","Mobile communication;Stress;Artificial neural networks;Correlation;Indexes;Biology","health care;smart phones","experience sampling;stress-related events;mobile phones;health care services;mobile electronic devices;Android smartphone","","2","","29","","22 Jul 2013","","","IEEE","IEEE Conferences"
"Audioclip: Extending Clip to Image, Text and Audio","A. Guzhov; F. Raue; J. Hees; A. Dengel","Deutsches Forschungszentrum für Künstliche Intelligenz GmbH, Kaiserslautern, Germany; Deutsches Forschungszentrum für Künstliche Intelligenz GmbH, Kaiserslautern, Germany; Deutsches Forschungszentrum für Künstliche Intelligenz GmbH, Kaiserslautern, Germany; Deutsches Forschungszentrum für Künstliche Intelligenz GmbH, Kaiserslautern, Germany","ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","27 Apr 2022","2022","","","976","980","The rapidly evolving field of sound classification has greatly benefited from the methods of other domains. Today, the trend is to fuse domain-specific tasks and approaches together, which provides the community with new outstanding models.We present AudioCLIP – an extension of the CLIP model that handles audio in addition to text and images. Utilizing the AudioSet dataset, our proposed model incorporates the ESResNeXt audio-model into the CLIP framework, thus enabling it to perform multimodal classification and keeping CLIP’s zero-shot capabilities.AudioCLIP achieves new state-of-the-art results in the Environmental Sound Classification (ESC) task and out-performs others by reaching accuracies of 97.15 % on ESC-50 and 90.07 % on UrbanSound8K. Further, it sets new baselines in the zero-shot ESC-task on the same datasets (69.40 % and 68.78 %, respectively).We also asses the influence of different training setups on the final performance of the proposed model. For the sake of reproducibility, our code is published.","2379-190X","978-1-6654-0540-9","10.1109/ICASSP43922.2022.9747631","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9747631","Audio;multimodal;zero-shot;classification","Training;Visualization;Codes;Fuses;Conferences;Signal processing;Market research","audio signal processing;feature extraction;image classification;learning (artificial intelligence);signal classification","audioclip;rapidly evolving field;domain-specific tasks;outstanding models;CLIP model;AudioSet dataset;CLIP framework;multimodal classification;Environmental Sound Classification task;ESC-50;zero-shot ESC-task","","16","","29","IEEE","27 Apr 2022","","","IEEE","IEEE Conferences"
"Comments on an optimal set of indices for a relational database","B. . -J. Falkowski","Datex Al, Gesellschaft fuer Angewandte Kunstliche Intelligenz mbH, Munchen, Germany","IEEE Transactions on Software Engineering","6 Aug 2002","1992","18","2","168","171","M. Y. L. Ip et al., (see ibid., vol.SE-9, p.135-43, 1983) solved the index selection problem for a relational database by reducing it to a classical knapsack problem and then applying an approximation algorithm. It is shown that this reduction process does not work in general by providing a counterexample, and its practical significance is discussed. It turns out that the main idea of Ip et al. need not be discarded. In particular, the approximation algorithm used can be adapted fairly easily to take care of the problems which were raised by the counterexample. In spite of its simplicity, this modification can lead to a reduced number of indices, which is rather attractive from a practical point of view.<>","1939-3520","","10.1109/32.121758","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=121758","","Relational databases;Costs;Approximation algorithms;Artificial intelligence;Indexes;NP-complete problem;Organizing","approximation theory;database theory;optimisation;relational databases","index selection problem;relational database;classical knapsack problem;approximation algorithm;reduction process","","5","1","6","IEEE","6 Aug 2002","","","IEEE","IEEE Journals"
"SemAttNet: Toward Attention-Based Semantic Aware Guided Depth Completion","D. Nazir; A. Pagani; M. Liwicki; D. Stricker; M. Z. Afzal","Deutsches Forschungszentrum für Künstliche Intelligenz (DFKI), Kaiserslautern, Germany; Deutsches Forschungszentrum für Künstliche Intelligenz (DFKI), Kaiserslautern, Germany; Department of Computer Science, Luleå University of Technology, Luleå, Sweden; Deutsches Forschungszentrum für Künstliche Intelligenz (DFKI), Kaiserslautern, Germany; Deutsches Forschungszentrum für Künstliche Intelligenz (DFKI), Kaiserslautern, Germany","IEEE Access","23 Nov 2022","2022","10","","120781","120791","Depth completion involves recovering a dense depth map from a sparse map and an RGB image. Recent approaches focus on utilizing color images as guidance images to recover depth at invalid pixels. However, color images alone are not enough to provide the necessary semantic understanding of the scene. Consequently, the depth completion task suffers from sudden illumination changes in RGB images (e.g., shadows). In this paper, we propose a novel three-branch backbone comprising color-guided, semantic-guided, and depth-guided branches. Specifically, the color-guided branch takes a sparse depth map and RGB image as an input and generates color depth which includes color cues (e.g., object boundaries) of the scene. The predicted dense depth map of color-guided branch along-with semantic image and sparse depth map is passed as input to semantic-guided branch for estimating semantic depth. The depth-guided branch takes sparse, color, and semantic depths to generate the dense depth map. The color depth, semantic depth, and guided depth are adaptively fused to produce the output of our proposed three-branch backbone. In addition, we also propose to apply semantic-aware multi-modal attention-based fusion block (SAMMAFB) to fuse features between all three branches. We further use CSPN++ with Atrous convolutions to refine the dense depth map produced by our three-branch backbone. Extensive experiments show that our model achieves state-of-the-art performance in the KITTI depth completion benchmark at the time of submission.","2169-3536","","10.1109/ACCESS.2022.3214316","European Project INFINITY(grant numbers:883293); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9918022","State-of-the-art depth completion approach on KITTI depth completion benchmark;attention-based fusion for depth completion;semantic-guided depth completion","Semantics;Image color analysis;Laser radar;Benchmark testing;Image color analysis;Predictive models;Reliability","feature extraction;image colour analysis;image fusion","Atrous convolutions;attention-based semantic aware guided depth completion;color depth;color images;color-guided branch;CSPN++;dense depth map;depth completion task;depth-guided branch;KITTI depth completion benchmark;RGB image;SAMMAFB;semantic image;semantic-aware multi-modal attention-based fusion block;semantic-aware multimodal attention;SemAttNet;sparse depth map;three-branch backbone","","9","","47","CCBYNCND","13 Oct 2022","","","IEEE","IEEE Journals"
"Analysis of interventions to optimize a pumping process in food production","M. Colombo; P. Jell; P. Theumer; A. Heim","Technologisches Institut für angewandte Künstliche Intelligenz GmbH, Weiden i.d.OPf., Germany; Technologisches Institut für angewandte Künstliche Intelligenz GmbH, Weiden i.d.OPf., Germany; Fraunhofer-Institut für Gießerei-, Composite- und Verarbeitungstechnik IGCV, Augsburg, Germany; Hochland Deutschland GmbH, Heimenkirch, Germany","2022 IEEE 5th International Conference on Industrial Cyber-Physical Systems (ICPS)","18 Jul 2022","2022","","","01","05","In this work in progress report we show the use of Causal Inference with a Double Machine Learning approach to derive recommendations to favorably intervene in a pumping process in food production. At this point the machine learning does not yield statistically significant results due to lack of sufficient data. We further look into strata we have built from the data to study treatment effects but are again limited by the amount of data available. An outline how we intend to proceed with the work is given.","","978-1-6654-9770-1","10.1109/ICPS51978.2022.9816993","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9816993","Causal Inference;Interventions;Food Production;Machine Learning","Conferences;Pumps;Production;Machine learning;Cyber-physical systems","food processing industry;learning (artificial intelligence);production engineering computing;pumps","pumping process;food production;causal inference;double machine learning","","","","7","IEEE","18 Jul 2022","","","IEEE","IEEE Conferences"
"A Smart Integration Layer for Smart City Business Applications","D. Spieldenner; T. Spieldenner","Agents and Simulated Reality, Deutsches Forschungszentrum für Künstliche Intelligenz GmbH (DFKI), Saarbrucken, Germany; Agents and Simulated Reality, Deutsches Forschungszentrum für Künstliche Intelligenz GmbH (DFKI), Saarbrucken, Germany","2020 4th International Conference on Smart Grid and Smart Cities (ICSGSC)","9 Nov 2020","2020","","","129","135","With large scale prototype projects like Dubai, New York or the Smart Cities Mission in India, Smart Cities are no longer a vague idea from the future but are getting more and more momentum in today's world. While the Internet of Things is emerging as the technology of choice to connect devices and services of all size and complexity to form a Smart City, the problem of interoperability between business layer applications is far from being solved. A remedy for this may come from the world of the Semantic Web: Lifting exchanged data to a semantic level not only allows to abstract from existing interfaces, a vast selection of already available ontologies for different use case scenarios facilitate the creation of an abstraction layer by already providing a commonly available vocabulary to describe functionality and data to be provided. In this paper, we present a light weight, domain specific semantic interoperability layer, and its use in a Smart City environment.","","978-1-7281-9404-2","10.1109/ICSGSC50906.2020.9248545","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9248545","smart city;api;interoperability;linked data","Vocabulary;Smart cities;Semantics;Prototypes;Ontologies;Interoperability;Business","business data processing;Internet of Things;ontologies (artificial intelligence);open systems;semantic Web;smart cities","domain specific semantic interoperability layer;smart cities mission;business layer applications;abstraction layer;smart integration layer;smart city business applications;smart city environment;large scale prototype projects;Dubai;New York;India;Internet of Things;semantic Web;use case scenarios","","1","","21","IEEE","9 Nov 2020","","","IEEE","IEEE Conferences"
"Modular augmented reality platform for smart operator in production environment","J. Um; J. Popper; M. Ruskowski","Technologie-Initative SmartFactory KL, Kaiserslautern, Germany; Technologie-Initative SmartFactory KL, Kaiserslautern, Germany; IFS-Innovative Fabriksysteme, Deutsches Forschungszentrum für Künstliche Intelligenz, Kaiserslautern, Germany","2018 IEEE Industrial Cyber-Physical Systems (ICPS)","21 Jun 2018","2018","","","720","725","The trend of mass customization requires highly flexible production systems, which pose a new challenge for workers. Numerous concepts using augmented reality technologies have been developed to offer support in manual assembly processes. Newer AR devices are equipped with more and more functions, such as microphones, speakers or multiple camera systems, which can be used to help workers. However, wearable devices offer only limited computational power and limited flexibility of their interface platform. This poses a challenge to heavy data transactions from various different sources and restrict the use for real-time responses, which are often necessary for applications in a factory. To overcome this limitation, the author of this paper proposes a combination of wearable devices with edge devices located on the shop floor. An augmented reality platform was constructed with modularized services by using the digital twin of the machine components and machine learning algorithms for object recognition. This is integrated in the factory environment to synchronize real machine components with their digital twin.","","978-1-5386-6531-2","10.1109/ICPHYS.2018.8390796","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8390796","Augmented reality;Smart Factory;Computer vision;Machine Learning;Digital Twin;Edge computing","Smart glasses;Servers;Cameras;Image edge detection;Machine learning algorithms;Production facilities","assembling;augmented reality;learning (artificial intelligence);mass production;object recognition;product customisation;production engineering computing;wearable computers","production environment;mass customization;highly flexible production systems;numerous concepts;augmented reality technologies;manual assembly processes;wearable devices;interface platform;real-time responses;modularized services;digital twin;machine components;factory environment;smart operator;AR devices;data transactions;modular augmented reality platform;machine learning algorithms;object recognition","","12","","13","IEEE","21 Jun 2018","","","IEEE","IEEE Conferences"
"High-Quality Rendering of Quartic Spline Surfaces on the GPU","G. Reis; F. Zeilfelder; M. Hering-Bertram; G. E. Farin; H. Hagen","Techno-und Wirtschaftsmathematik, Fraunhofer ITWM, Martin Hering-Bertram, Fraunhofer-Institut, Kaiserslautern, Germany; Department of Computer Science and Engineering College of Engineering, University of Kaiserslautern, Kaiserslautern, Germany; TU Darmstadt, Fachbereich Informatik, Technical University of Darmstadt, Darmstadt, Germany; PRISM, Computer Science and Engineering, Arizona State University, Tempe, AZ, USA; German Research Center for Artificial Intelligence .(DFKI), CC Human-Centered Visualization, Deutsches Forschungszentrum fuer Kuenstliche Intelligenz GmbH, Kaiserslautern, Germany","IEEE Transactions on Visualization and Computer Graphics","15 Jul 2008","2008","14","5","1126","1139","We present a novel GPU-based algorithm for high-quality rendering of bivariate spline surfaces. An essential difference to the known methods for rendering graph surfaces is that we use quartic smooth splines on triangulations rather than triangular meshes. Our rendering approach is direct since we do not use an intermediate tessellation but rather compute ray-surface intersections (by solving quartic equations numerically) as well as surface normals (by using Bernstein-Bezier techniques) for Phong illumination on the GPU. Inaccurate shading and artifacts appearing for triangular tesselated surfaces are completely avoided. Level of detail is automatic since all computations are done on a per fragment basis. We compare three different (quasi-) interpolating schemes for uniformly sampled gridded data, which differ in the smoothness and the approximation properties of the splines. The results show that our hardware-based renderer leads to visualizations (including texturing, multiple light sources, environment mapping, and so forth) of highest quality.","1941-0506","","10.1109/TVCG.2008.66","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4509429","Raytracing;Spline and piecewise polynomial approximation;Raytracing;Spline and piecewise polynomial approximation","Spline;Rendering (computer graphics);Data visualization;Piecewise linear techniques;Lighting;Piecewise linear approximation;Ray tracing;Large-scale systems;Polynomials;Artificial intelligence","interpolation;rendering (computer graphics);splines (mathematics)","high-quality rendering;quartic spline surfaces;bivariate spline surfaces;triangulations;intermediate tessellation;compute ray-surface intersections;quartic equations;interpolating schemes;uniformly sampled gridded data;smoothness property;approximation property","Algorithms;Computer Graphics;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Reproducibility of Results;Sensitivity and Specificity","5","","50","IEEE","10 Jun 2008","","","IEEE","IEEE Journals"
"Bias-Aware Loss for Training Image and Speech Quality Prediction Models from Multiple Datasets","G. Mittag; S. Zadtootaghaj; T. Michael; B. Naderi; S. Möller","Quality and Usability Lab, Technische Universität Berlin, Berlin, Germany; Quality and Usability Lab, Technische Universität Berlin, Berlin, Germany; Quality and Usability Lab, Technische Universität Berlin, Berlin, Germany; Quality and Usability Lab, Technische Universität Berlin, Berlin, Germany; Quality and Usability Lab, Technische Universität Berlin, Berlin, Germany","2021 13th International Conference on Quality of Multimedia Experience (QoMEX)","30 Jun 2021","2021","","","97","102","The ground truth used for training image, video, or speech quality prediction models is based on the Mean Opinion Scores (MOS) obtained from subjective experiments. Usually, it is necessary to conduct multiple experiments, mostly with different test participants, to obtain enough data to train quality models based on machine learning. Each of these experiments is subject to an experiment-specific bias, where the rating of the same file may be substantially different in two experiments (e.g. depending on the overall quality distribution). These different ratings for the same distortion levels confuse neural networks during training and lead to lower performance. To overcome this problem, we propose a bias-aware loss function that estimates each dataset's biases during training with a linear function and considers it while optimising the network weights. We prove the efficiency of the proposed method by training and validating quality prediction models on synthetic and subjective image and speech quality datasets.","2472-7814","978-1-6654-3589-5","10.1109/QoMEX51781.2021.9465384","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9465384","Speech Quality;Image Quality;DNN","Training;Computational modeling;Neural networks;Machine learning;Predictive models;Tools;Streaming media","distortion;image processing;learning (artificial intelligence);neural nets;quality of experience;speech processing","training image;speech quality prediction models;mean opinion scores;subjective experiments;test participants;experiment-specific bias;quality distribution;bias-aware loss function;dataset bias;subjective image;speech quality datasets;MOS;machine learning;distortion levels;neural networks;linear function;network weight optimisation;quality prediction model training;synthetic image;quality prediction model validation","","2","","25","IEEE","30 Jun 2021","","","IEEE","IEEE Conferences"
"Sentinel-1-Based Water and Flood Mapping: Benchmarking Convolutional Neural Networks Against an Operational Rule-Based Processing Chain","M. Helleis; M. Wieland; C. Krullikowski; S. Martinis; S. Plank","German Remote Sensing Data Center (DFD), German Aerospace Center (DLR), Oberpfaffenhofen, Germany; German Remote Sensing Data Center (DFD), German Aerospace Center (DLR), Oberpfaffenhofen, Germany; German Remote Sensing Data Center (DFD), German Aerospace Center (DLR), Oberpfaffenhofen, Germany; German Remote Sensing Data Center (DFD), German Aerospace Center (DLR), Oberpfaffenhofen, Germany; German Remote Sensing Data Center (DFD), German Aerospace Center (DLR), Oberpfaffenhofen, Germany","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","8 Mar 2022","2022","15","","2023","2036","In this study, the effectiveness of several convolutional neural network architectures (AlbuNet-34/FCN/DeepLabV3+/U-Net/U-Net++) for water and flood mapping using Sentinel-1 amplitude data is compared to an operational rule-based processor (S-1FS). This comparison is made using a globally distributed dataset of Sentinel-1 scenes and the corresponding ground truth water masks derived from Sentinel-2 data to evaluate the performance of the classifiers on a global scale in various environmental conditions. The impact of using single versus dual-polarized input data on the segmentation capabilities of AlbuNet-34 is evaluated. The weighted cross entropy loss is combined with the Lovász loss and various data augmentation methods are investigated. Furthermore, the concept of atrous spatial pyramid pooling used in DeepLabV3+ and the multiscale feature fusion inherent in U-Net++ are assessed. Finally, the generalization capacity of AlbuNet-34 is tested in a realistic flood mapping scenario by using additional data from two flood events and the Sen1Floods11 dataset. The model trained using dual polarized data outperforms the S-1FS significantly and increases the intersection over union (IoU) score by 5%. Using a weighted combination of the cross entropy and the Lovász loss increases the IoU score by another 2%. Geometric data augmentation degrades the performance while radiometric data augmentation leads to better testing results. FCN/DeepLabV3+/U-Net/U-Net++ perform not significantly different to AlbuNet-34. Models trained on data showing no distinct inundation perform very well in mapping the water extent during two flood events, reaching IoU scores of 0.96 and 0.94, respectively, and perform comparatively well on the Sen1Floods11 dataset.","2151-1535","","10.1109/JSTARS.2022.3152127","German Federal Ministry of Education and Research; Künstliche Intelligenz zur Analyse von Erdbeobachtungs- und Internetdaten zur Entscheidungsunterstützung im Katastrophenfall(grant numbers:13N15525); Helmholtz Artificial Intelligence Cooperation Unit; AI for Near Real Time Satellite-based Flood Response(grant numbers:ZT-IPF-5-39); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9714780","Convolutional neural networks;data augmentation;semantic segmentation;Sen1Floods11;Sentinel-1;Sentinel-2;surface water monitoring","Floods;Data models;Synthetic aperture radar;Convolutional neural networks;Training;Sea surface;Thresholding (Imaging)","convolutional neural nets;emergency management;entropy;feature extraction;floods;geophysical image processing;image classification;image fusion;image segmentation;learning (artificial intelligence);neural nets;remote sensing","convolutional neural networks;operational rule-based processing chain;operational rule-based processor;S-1FS;globally distributed dataset;geometric data augmentation;Sentinel-1-based water mapping;flood mapping;AlbuNet-34;FCN;DeepLabV3+;U-Net;U-Net++;ground truth water masks;environmental conditions;dual-polarized input data;single-polarized input data;spatial pyramid pooling;multiscale feature fusion","","8","","72","CCBY","16 Feb 2022","","","IEEE","IEEE Journals"
"Special Issue on Emerging Topics on Development and Learning","M. -J. Escobar; N. Navarro-Guerrero; J. Ruiz-Del-Solar; G. Sandini","Department of Electronic Engineering & AC3E Center, Universidad Técnica Federico Santa María, Valparaíso, Chile; Robotics Innovation Center, Deutsches Forschungszentrum für Künstliche Intelligenz, Kaiserslautern, Germany; Department of Electrical Egineering & AMTC Cente, Universidad de Chile, Santiago, Chile; Italian Institute of Technology, Genoa, Italy","IEEE Transactions on Cognitive and Developmental Systems","10 Jun 2022","2022","14","2","255","257","This special issue includes state-of-the-art research on emerging topics on development and learning in natural and artificial systems. In addition to new submissions, the special issue includes extensions of the paper awarded the Best Paper Award at ICDL-EpiRob 2020—the 10th Joint IEEE Conference on Development and Learning and Epigenetic Robotics 2020 (https://cdstc.gitlab.io/icdl-2020/).","2379-8939","","10.1109/TCDS.2022.3165964","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793369","","Special issues and sections;Robots;Learning (artificial intelligence);Cognitive robotics;Predictive models;Ethical aspects;Reinforcement learning;Biological system modeling","","","","","","0","IEEE","10 Jun 2022","","","IEEE","IEEE Journals"
